{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRntSkjIpCx1",
        "outputId": "33e1aa22-5a96-4e3c-aba7-bd510e30a902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "# !pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove extra white spaces\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "raw_text = \"I love my country, Pakistan. It has four Provinces.\"\n",
        "clean_text = preprocess_text(raw_text)\n",
        "print(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLcHmtznqop-",
        "outputId": "32bf5e96-ea49-4fe8-fcd3-65204e4b9ad6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love my country pakistan it has four provinces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import pos_tag\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "# Tokenize into words\n",
        "words = word_tokenize(clean_text)\n",
        "print(\"Tokenized Words:\", words)\n",
        "\n",
        "# Tokenize into sentences\n",
        "sentences = sent_tokenize(clean_text)\n",
        "print(\"Tokenized Sentences:\", sentences)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = pos_tag(words)\n",
        "\n",
        "# Extract POS tags\n",
        "pos_categories = [tag[1] for tag in pos_tags]\n",
        "\n",
        "# Count POS categories\n",
        "pos_counts = Counter(pos_categories)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Initialize WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize each word\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pN3fsGcq83e",
        "outputId": "17b58bc6-f556-4afb-9e94-6010c9e20018"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['i', 'love', 'my', 'country', 'pakistan', 'it', 'has', 'four', 'provinces']\n",
            "Tokenized Sentences: ['i love my country pakistan it has four provinces']\n",
            "Lemmatized Words: ['i', 'love', 'my', 'country', 'pakistan', 'it', 'ha', 'four', 'province']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process the text using spaCy\n",
        "doc = nlp(clean_text)\n",
        "# Customizing dependency visualization\n",
        "# options = {\"compact\": True, \"color\": \"blue\", \"bg\": \"#ffffff\",\n",
        "#            \"font\": \"Source Sans Pro\"}\n",
        "# Visualize named entities using displaCy\n",
        "# displacy.render(doc, style=\"dep\", jupyter=True, options=options)\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "WtpwXP93rNcN",
        "outputId": "3106e1b0-b4e3-4c32-b055-b4f7e64e52d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">i love my country \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    pakistan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " it has \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    four\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " provinces</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}